https://www.ijert.org/email-based-spam-detection

import string
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer  #String to numeric.When maximum column is string
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import pickle
from sklearn.preprocessing import LabelEncoder

import nltk 
nltk.download('punkt')
nltk.download('stopwords') 
from nltk.corpus import stopwords

data = pd.read_csv('spam.csv')
data
data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)
data
data.info()
data.drop_duplicates(inplace=True)
print(data.shape)
data.dropna(inplace=True)
data.info()
le = LabelEncoder()
data['v1'] = le.fit_transform(data['v1'])
print(data['v1'])
data['v2'] = data['v2'].str.replace('Subject', '')
data.head()
punctuations_list = string.punctuation
def remove_punctuations(v2):
	temp = str.maketrans('', '', punctuations_list)
	return v2.translate(temp)

data['v2']= data['v2'].apply(lambda x: remove_punctuations(x))
data.head()

stp_words = stopwords.words('english')
def clean_message(message):
    clean_message = " ".join(word for word in message.split() if word not in stp_words)
    return clean_message

data['v2'] = data['v2'].apply(clean_message)
print(data.v2)
data['v1'].value_counts()
trans = data['v1'].value_counts()
print(trans)
trans.plot.bar()
plt.title('v1')
plt.xlabel("Spam or Not-Spam")
plt.show()
x = data['v1'].value_counts()
y = 'Not-Spam', 'Spam'

plt.pie(x,labels = y,autopct = '%1.1f%%',startangle = 90,colors = ['yellow','red'])
plt.title('Spam or Not-Spam')
plt.show()
consolidated = ' '.join(word for word in data['v2'][data['v1'] == 0].astype(str))
wordCloud = WordCloud(width = 1600,height = 800,max_font_size = 110)
plt.figure(figsize = (15,10))
plt.imshow(wordCloud.generate(consolidated),interpolation = 'bilinear')
plt.axis('off')
plt.show()
consolidated = ' '.join(word for word in data['v2'][data['v1'] == 1].astype(str))
wordCloud = WordCloud(width = 1600,height = 800,max_font_size = 110)
plt.figure(figsize = (15,10))
plt.imshow(wordCloud.generate(consolidated),interpolation = 'bilinear')
plt.axis('off')
plt.show()
cv = TfidfVectorizer(max_features=2500)
X = cv.fit_transform(data['v2']).toarray()
print(X)

Y = data['v1']

with open('cv.pkl','wb') as file:
    pickle.dump(cv, file)
from imblearn.over_sampling import SMOTE

#Initialize SMOTE with a sampling strategy (you can adjust it as needed)
smote = SMOTE(sampling_strategy = 'auto',random_state = 42)

#Apply SMOTE to resample the dataset
X_resampled,y_resampled = smote.fit_resample(X,Y)
y_resampled.value_counts()
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.25)
print(x_train)
print(x_test)
print(x_train.shape)
print(x_test.shape)
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

model = DecisionTreeClassifier()

#Model fitting
model.fit(x_train,y_train)

#testing the model
pred = model.predict(x_test)

#model accuracy
print(accuracy_score(y_test,pred))
print(pred)

import pickle
pickle.dump(model,open('model_save.pkl','wb'))

model = pickle.load(open('model_save.pkl','rb'))
def predict_sentiment(message_text):
    #Preprocess the input review
    cleaned_message = clean_message(message_text)
    #Transfrom the review using the TF-IDF vectorizer    
    transformed_message = cv.transform([cleaned_message]).toarray()
    #Predict sentiment using the trained model    
    prediction = model.predict(transformed_message)

    if prediction[0] == 1:
        return 'Spam'
    else:
        return 'Not-Spam'

#Now you can use the predict_sentiment function to classify reviews
input_message = input('Enter the Mail::')
result = predict_sentiment(input_message)
print(f'This Mail is {result}')